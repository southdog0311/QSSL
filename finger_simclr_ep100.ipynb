{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n",
      "11.8\n",
      "8700\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可用的 GPU 裝置數量: 1\n",
      "已設置使用的 GPU 裝置: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 檢查可用的 GPU 裝置\n",
    "device_count = torch.cuda.device_count()\n",
    "print(\"可用的 GPU 裝置數量:\", device_count)\n",
    "\n",
    "# 設置 CUDA 裝置\n",
    "device_index = 0  # 要使用的 GPU 裝置索引\n",
    "torch.cuda.set_device(device_index)\n",
    "print(\"已設置使用的 GPU 裝置:\", torch.cuda.current_device())\n",
    "\n",
    "# 其他程式碼，執行 CUDA 操作等\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "tensor([1., 4., 9.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 檢查CUDA是否可用\n",
    "if torch.cuda.is_available():\n",
    "    # 列印CUDA版本\n",
    "    print(torch.version.cuda)\n",
    "    # 創建一個Tensor並將其移動到CUDA設備上\n",
    "    device = torch.device('cuda')\n",
    "    x = torch.tensor([1.0, 2.0, 3.0])\n",
    "    x = x.to(device)\n",
    "    # 執行一些CUDA操作\n",
    "    y = x ** 2\n",
    "    # 將結果移回CPU並列印\n",
    "    y = y.to('cpu')\n",
    "    print(y)\n",
    "else:\n",
    "    print('CUDA不可用')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==> Training Setting: \n",
      " Namespace(datadir='data/', arch='resnet18', workers=8, epochs=100, start_epoch=0, epoch_size=4800, classes=600, batch_size=32, lr=0.001, schedule=[320, 360], momentum=0.9, weight_decay=0.0001, print_freq=10, save_freq=1, save_batches=False, resume='', seed=None, gpu=0, fdim=128, temperature=0.07, sigtemp=1.0, batchnorm=False, identity=False, width=8, layers=2, quantum=False, q_backend='qasm_simulator', encoding='vector', q_ansatz='sim_circ_14_half', q_sweeps=1, activation='null', shots=100, save_dhs=False, save_overlap=False, submission_time='', yaspify=False, slurm=False, worker_id=0, yaspi_defaults_path='yaspi_train_defaults.json', exp_config=WindowsPath('yaspi_train.json'))\n",
      "==============================\n",
      "==============================\n",
      "Use GPU: 0 for training\n",
      "==============================\n",
      "=> creating model 'resnet18'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sam22\\AppData\\Local\\Temp\\ipykernel_21212\\676334173.py:251: UserWarning: You have chosen a specific GPU. This will completely disable data parallelism.\n",
      "  warnings.warn('You have chosen a specific GPU. This will completely '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 52, 48]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 52, 48]             128\n",
      "              ReLU-3           [-1, 64, 52, 48]               0\n",
      "         MaxPool2d-4           [-1, 64, 26, 24]               0\n",
      "            Conv2d-5           [-1, 64, 26, 24]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 26, 24]             128\n",
      "              ReLU-7           [-1, 64, 26, 24]               0\n",
      "            Conv2d-8           [-1, 64, 26, 24]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 26, 24]             128\n",
      "             ReLU-10           [-1, 64, 26, 24]               0\n",
      "       BasicBlock-11           [-1, 64, 26, 24]               0\n",
      "           Conv2d-12           [-1, 64, 26, 24]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 26, 24]             128\n",
      "             ReLU-14           [-1, 64, 26, 24]               0\n",
      "           Conv2d-15           [-1, 64, 26, 24]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 26, 24]             128\n",
      "             ReLU-17           [-1, 64, 26, 24]               0\n",
      "       BasicBlock-18           [-1, 64, 26, 24]               0\n",
      "           Conv2d-19          [-1, 128, 13, 12]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 13, 12]             256\n",
      "             ReLU-21          [-1, 128, 13, 12]               0\n",
      "           Conv2d-22          [-1, 128, 13, 12]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 13, 12]             256\n",
      "           Conv2d-24          [-1, 128, 13, 12]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 13, 12]             256\n",
      "             ReLU-26          [-1, 128, 13, 12]               0\n",
      "       BasicBlock-27          [-1, 128, 13, 12]               0\n",
      "           Conv2d-28          [-1, 128, 13, 12]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 13, 12]             256\n",
      "             ReLU-30          [-1, 128, 13, 12]               0\n",
      "           Conv2d-31          [-1, 128, 13, 12]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 13, 12]             256\n",
      "             ReLU-33          [-1, 128, 13, 12]               0\n",
      "       BasicBlock-34          [-1, 128, 13, 12]               0\n",
      "           Conv2d-35            [-1, 256, 7, 6]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 7, 6]             512\n",
      "             ReLU-37            [-1, 256, 7, 6]               0\n",
      "           Conv2d-38            [-1, 256, 7, 6]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 7, 6]             512\n",
      "           Conv2d-40            [-1, 256, 7, 6]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 7, 6]             512\n",
      "             ReLU-42            [-1, 256, 7, 6]               0\n",
      "       BasicBlock-43            [-1, 256, 7, 6]               0\n",
      "           Conv2d-44            [-1, 256, 7, 6]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 7, 6]             512\n",
      "             ReLU-46            [-1, 256, 7, 6]               0\n",
      "           Conv2d-47            [-1, 256, 7, 6]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 7, 6]             512\n",
      "             ReLU-49            [-1, 256, 7, 6]               0\n",
      "       BasicBlock-50            [-1, 256, 7, 6]               0\n",
      "           Conv2d-51            [-1, 512, 4, 3]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 4, 3]           1,024\n",
      "             ReLU-53            [-1, 512, 4, 3]               0\n",
      "           Conv2d-54            [-1, 512, 4, 3]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 4, 3]           1,024\n",
      "           Conv2d-56            [-1, 512, 4, 3]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 4, 3]           1,024\n",
      "             ReLU-58            [-1, 512, 4, 3]               0\n",
      "       BasicBlock-59            [-1, 512, 4, 3]               0\n",
      "           Conv2d-60            [-1, 512, 4, 3]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 4, 3]           1,024\n",
      "             ReLU-62            [-1, 512, 4, 3]               0\n",
      "           Conv2d-63            [-1, 512, 4, 3]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 4, 3]           1,024\n",
      "             ReLU-65            [-1, 512, 4, 3]               0\n",
      "       BasicBlock-66            [-1, 512, 4, 3]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 8]           4,104\n",
      "           Linear-69                    [-1, 8]              72\n",
      "        LeakyReLU-70                    [-1, 8]               0\n",
      "           Linear-71                    [-1, 8]              72\n",
      "        LeakyReLU-72                    [-1, 8]               0\n",
      "           Linear-73                    [-1, 8]              64\n",
      "      BatchNorm1d-74                    [-1, 8]              16\n",
      "             ReLU-75                    [-1, 8]               0\n",
      "           Linear-76                    [-1, 8]              72\n",
      "           ResNet-77                    [-1, 8]               0\n",
      "================================================================\n",
      "Total params: 11,180,912\n",
      "Trainable params: 11,180,912\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 12.73\n",
      "Params size (MB): 42.65\n",
      "Estimated Total Size (MB): 55.50\n",
      "----------------------------------------------------------------\n",
      "Training model saved at model\\selfsup\\simclr\\SimCLR-resnet18-quantum_False-classes_600-netwidth_8-nlayers_2-identity_False-epochsize_4800-bsize_32-tepochs_100_0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
    "import argparse\n",
    "import getpass\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "# Imports for yaspi\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchsummary\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from numpy.linalg import matrix_power\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import cv2\n",
    "\n",
    "import hybrid_resnet\n",
    "import moco.builder\n",
    "import moco.loader\n",
    "from yaspi.yaspi import Yaspi\n",
    "\n",
    "import os\n",
    "\n",
    "# +\n",
    "# # !pip install ipywidgets\n",
    "# # !jupyter nbextension enable --py widgetsnbextension\n",
    "# # !python --version\n",
    "# import torch\n",
    "# print(torch.version.cuda)\n",
    "# print(torch.cuda.is_available())\n",
    "# -\n",
    "\n",
    "os.environ['KMP_WARNINGS'] = '1'\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(models.__dict__[name]))\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Quantum self-sup training')\n",
    "parser.add_argument('-d', '--datadir', metavar='DIR', default='./data', help='path to dataset')\n",
    "parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet18',\n",
    "                    choices=model_names,\n",
    "                    help='model arch: {\"|\".join(model_names)} (default: resnet50)')\n",
    "parser.add_argument('-j', '--workers', default=8, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 32)')\n",
    "parser.add_argument('--epochs', default=30, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--epoch-size', default=4800, type=int,\n",
    "                    help='size of training set to use (default:55270, size of SOCOFing Fingerprint Dataset)')\n",
    "parser.add_argument('--classes', default=600, type=int,\n",
    "                    help='Number of classes in the training set (default:600)')\n",
    "parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('--lr', '--learning-rate', default=1e-3, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--schedule', default=[320, 360], nargs='*', type=int,\n",
    "                    help='learning rate schedule (when to drop lr by 10x)')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum of SGD solver')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('-p', '--print-freq', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--save-freq', default=1, type=int,\n",
    "                    metavar='N', help='Save trained model every x epochs or batches (see --save-batches)')\n",
    "parser.add_argument('--save-batches', dest='save_batches', action='store_true',\n",
    "                    help='Save model every x batches rather than epochs')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training. ')\n",
    "parser.add_argument('--gpu', default=None, type=int,\n",
    "                    help='GPU id to use.')\n",
    "\n",
    "parser.add_argument('--fdim', default=128, type=int,\n",
    "                    help='feature dimension (default: 128)')\n",
    "\n",
    "parser.add_argument('--temperature', default=0.07, type=float,\n",
    "                    help='softmax temperature (default: 0.07)')\n",
    "\n",
    "parser.add_argument('--sigtemp', default=1.0, type=float,\n",
    "                    help='Pre-quantum Sigmoid temperature (default: 1.0)')\n",
    "\n",
    "parser.add_argument('--batchnorm', dest='batchnorm', action='store_true',\n",
    "                    help='If enabled, apply BatchNorm1d to the input of the pre-quantum Sigmoid.')\n",
    "\n",
    "parser.add_argument('--identity', dest='identity', action='store_true',\n",
    "                    help='If enabled, the test network is replaced by the identity. The previous and subsequent layer '\n",
    "                         'still compress to n_qubits however.')\n",
    "parser.add_argument('-w', '--width', type=int, default=8,\n",
    "                    help='Width of the test network (default: 8). If quantum, this is the number of qubits.')\n",
    "parser.add_argument('--layers', type=int, default=2,\n",
    "                    help='Number of layers in the test network (default: 2).')\n",
    "\n",
    "parser.add_argument('-q', '--quantum', dest='quantum', action='store_true',\n",
    "                    help='If enabled, use a minimised version of ResNet-18 with QNet as the final layer')\n",
    "parser.add_argument('--q_backend', type=str, default='qasm_simulator',\n",
    "                    help='Type of backend simulator to run quantum circuits on (default: qasm_simulator)')\n",
    "\n",
    "parser.add_argument('--encoding', type=str, default='vector',\n",
    "                    help='Data encoding method (default: vector)')\n",
    "parser.add_argument('--q_ansatz', type=str, default='sim_circ_14_half',\n",
    "                    help='Variational ansatz method (default: sim_circ_14_half)')\n",
    "parser.add_argument('--q_sweeps', type=int, default=1,\n",
    "                    help='Number of ansatz sweeeps.')\n",
    "parser.add_argument('--activation', type=str, default='null',\n",
    "                    help='Quantum layer activation function type (default: null)')\n",
    "parser.add_argument('--shots', type=int, default=100,\n",
    "                    help='Number of shots for quantum circuit evaluations.')\n",
    "parser.add_argument('--save-dhs', action='store_true',\n",
    "                    help='If enabled, compute the Hilbert-Schmidt distance of the quantum statevectors belonging to'\n",
    "                         ' each class. Only works for -q and --classes 2.')\n",
    "parser.add_argument('--save-overlap', action='store_true',\n",
    "                    help='If enabled, compute the overlap between statevectors corresponding to positive training'\n",
    "                         'pairs. Saves average for overlap of each batch.')\n",
    "\n",
    "parser.add_argument('--submission-time', type=str, default='',\n",
    "                    help='Date and time of yaspify submission to create output directory.')\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# cluster grid optionsssh\n",
    "parser.add_argument(\"--yaspify\", action=\"store_true\")\n",
    "parser.add_argument(\"--slurm\", action=\"store_true\")\n",
    "parser.add_argument(\"--worker_id\", type=int, default=0)\n",
    "parser.add_argument(\"--yaspi_defaults_path\", default=\"yaspi_train_defaults.json\")\n",
    "parser.add_argument(\"--exp_config\", default=\"yaspi_train.json\", type=Path)\n",
    "\n",
    "# list to draw graph\n",
    "batch_acc2_list = []\n",
    "train_acc2_list = []\n",
    "batches_list = []\n",
    "train_loss_list = []\n",
    "args = parser.parse_args(args=['--gpu', '0', '--lr', '1e-3', '-b', '32', '-d', 'data/', '-w', '8', '--epochs', '100']) # for jupyter notebook\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# +\n",
    "# 2023-3-12 custom dataset created by Allen LIN\n",
    "\n",
    "class fingerprintDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.targets = self.img_labels.iloc[:, 1] # label of the dataset\n",
    "        self.target_transform = target_transform\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[0, 0])\n",
    "        image = cv2.imread(img_path)\n",
    "        self.data = np.empty((len(self.img_labels), *image.shape), dtype=np.uint8)\n",
    "        for i in range(len(self.img_labels)):\n",
    "            self.data[i] = image\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = cv2.imread(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "\n",
    "# -\n",
    "\n",
    "def main():\n",
    "#     args = parser.parse_args() # for command line\n",
    "    # --------------------------------------------------------------------------------\n",
    "    # Support cluster grid search\n",
    "    if args.yaspify:\n",
    "        # Load cluster job options\n",
    "        with open(args.yaspi_defaults_path, \"r\") as f:\n",
    "            yaspi_defaults = json.load(f)\n",
    "        # Load experiment hyperparams for the demo\n",
    "        with open(args.exp_config, \"r\") as f:\n",
    "            exp_kwargs = json.load(f)\n",
    "        cmd_args = sys.argv\n",
    "        cmd_args.remove(\"--yaspify\")\n",
    "        cmd_args.append('--submission-time')\n",
    "        cmd_args.append(datetime.now().strftime(r\"%Y-%m-%d_%H-%M-%S\"))\n",
    "        base_cmd = f\"python {' '.join(cmd_args)} --slurm\"\n",
    "        job_name = f\"train-simclr-{args.exp_config.stem}\"\n",
    "        # compute cartesian product of options\n",
    "        job_queue = []\n",
    "        hparam_vals = [x for x in exp_kwargs.values()]\n",
    "        grid_vals = list(itertools.product(*hparam_vals))\n",
    "        hparams = list(exp_kwargs)\n",
    "\n",
    "        for vals in grid_vals:\n",
    "            kwargs = \" \".join(f\"--{hparam} {val}\" for hparam, val in zip(hparams, vals))\n",
    "            job_queue.append(f'\"{kwargs}\"')\n",
    "        job = Yaspi(\n",
    "            cmd=base_cmd,\n",
    "            job_queue=\" \".join(job_queue),\n",
    "            job_name=job_name,\n",
    "            job_array_size=len(job_queue),\n",
    "            **yaspi_defaults,\n",
    "        )\n",
    "        job.submit(watch=True, conserve_resources=5)\n",
    "    else:\n",
    "        if args.slurm:\n",
    "            # add any cluster-specific setup you need to do here. E.g. I run a script\n",
    "            # sets up some temporary symlinks\n",
    "            if getpass.getuser() == \"albanie\":\n",
    "                os.system(str(Path.home() / \"configure_tmp_data.sh\"))\n",
    "\n",
    "        print('=' * 30)\n",
    "        print('==> Training Setting: \\n {}'.format(args))\n",
    "        print('=' * 30)\n",
    "        if args.seed is not None:\n",
    "            random.seed(args.seed)\n",
    "            torch.manual_seed(args.seed)\n",
    "            cudnn.deterministic = True\n",
    "            warnings.warn('You have chosen to seed training. '\n",
    "                          'This will turn on the CUDNN deterministic setting, '\n",
    "                          'which can slow down your training considerably! '\n",
    "                          'You may see unexpected behavior when restarting '\n",
    "                          'from checkpoints.')\n",
    "\n",
    "        if args.gpu is not None:\n",
    "            warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                          'disable data parallelism.')\n",
    "\n",
    "        ngpus_per_node = torch.cuda.device_count()\n",
    "        # Simply call main_worker function\n",
    "        main_worker(args.gpu, ngpus_per_node, args)\n",
    "\n",
    "\n",
    "# +\n",
    "def main_worker(gpu, ngpus_per_node, args):\n",
    "    args.gpu = gpu\n",
    "    if args.gpu is not None:\n",
    "        print('=' * 30)\n",
    "        print(\"Use GPU: {} for training\".format(args.gpu))\n",
    "        print('=' * 30)\n",
    "\n",
    "    # create model\n",
    "    print(\"=> creating model '{}'\".format(args.arch))\n",
    "    model = moco.builder.SimCLR(hybrid_resnet.resnet18, args.width, args)\n",
    "\n",
    "    if args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model = model.cuda(args.gpu)\n",
    "    else:\n",
    "        print('=> Training with CPU.')\n",
    "\n",
    "    torchsummary.summary(model, (3, 103, 96))\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = None\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "    # optionally resume from a checkpoint\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "            if args.gpu is None:\n",
    "                checkpoint = torch.load(args.resume)\n",
    "            else:\n",
    "                # Map model to be loaded to specified single gpu.\n",
    "                loc = 'cuda:{}'.format(args.gpu)\n",
    "                checkpoint = torch.load(args.resume, map_location=loc)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    current_dir = os.getcwd()\n",
    "    annotations_file = os.path.join(current_dir, \"kaggle_fingerprint\", \"kaggle_fingerprint_annotations.csv\")\n",
    "    img_dir = os.path.join(current_dir, \"All\")\n",
    "   \n",
    "    # Normalization for SOCOFing Fingerprint dataset\n",
    "    normalize = transforms.Normalize(mean=[0.5071, 0.5071, 0.5071],\n",
    "                                     std=[0.4107, 0.4107, 0.4107])\n",
    "\n",
    "    augmentation = [\n",
    "        transforms.ToPILImage(), # to PIL format\n",
    "        transforms.RandomResizedCrop(32, scale=(0.2, 1.0)),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)  # not strengthened\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        # transforms.RandomApply([moco.loader.GaussianBlur([.1, 2.])], p=0.5),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]\n",
    "    \n",
    "    transform = transforms.Compose(augmentation)\n",
    "    train_dataset = fingerprintDataset(annotations_file, img_dir,\n",
    "                                       transform=moco.loader.TwoCropsTransform(\n",
    "                                         transforms.Compose(augmentation)))\n",
    "#     image, label = train_dataset[0]\n",
    "#     print(f'image: {image}, label: {label}')\n",
    "#     print(train_dataset.data.shape)\n",
    "\n",
    "\n",
    "#     train_labels = np.array(train_dataset.targets)\n",
    "#     num_classes = args.classes\n",
    "#     train_idx = np.array(\n",
    "#         [np.where(train_labels == i)[0][:int(args.epoch_size / num_classes)+1] for i in range(0, num_classes+1)], dtype=object).flatten()\n",
    "#     train_idx = np.hstack(train_idx)\n",
    "#     train_dataset.targets = train_labels[train_idx]\n",
    "#     train_dataset.data = train_dataset.data[train_idx]\n",
    "\n",
    "#     if len(train_idx) < args.epoch_size:\n",
    "#         logging.warning(\n",
    "#             f\"Requested epoch size ({args.epoch_size}) is greater than available images for chosen classes \"\n",
    "#             f\"({len(train_idx)}). Training will use the set of available images, output files will save requested \"\n",
    "#             f\"epoch size.\")\n",
    "\n",
    "    train_sampler = None\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler, drop_last=True)\n",
    "\n",
    "    model_path = create_output_model_path(args)\n",
    "    print('Training model saved at {}'.format(model_path))\n",
    "\n",
    "    with open(os.path.join(model_path, \"train_args.json\"), 'w') as fp:\n",
    "        args.exp_config = str(args.exp_config)\n",
    "        json.dump(vars(args), fp)\n",
    "\n",
    "    repr_network_params = []\n",
    "    dhs_list = []\n",
    "    dhs_positive_pair_list = []\n",
    "    overlap_list = []\n",
    "    loss_list = []\n",
    "\n",
    "    # Wipe metric information accumulated during TorchSummary\n",
    "    if hasattr(model.encoder.repr_network[0], 'qnn'):\n",
    "        model.encoder.repr_network[0].qnn.gradients = []\n",
    "        model.encoder.repr_network[0].qnn.statevectors = []\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, model_path, criterion, optimizer, epoch, args, repr_network_params, dhs_list,\n",
    "                dhs_positive_pair_list,\n",
    "                overlap_list, loss_list)\n",
    "        \n",
    "        train_loss_list.append(np.mean(loss_list))\n",
    "        train_acc2_list.append(np.mean(batch_acc2_list))\n",
    "\n",
    "        if not args.save_batches:\n",
    "            fname = 'checkpoint_{:04d}.path.tar'.format(epoch)\n",
    "            checkpoint_name = os.path.join(model_path, fname)\n",
    "            if epoch % args.save_freq == 0 or epoch == args.epochs - 1:\n",
    "                ckpt = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'arch': args.arch,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'loss': loss_list\n",
    "                }\n",
    "                save_checkpoint(ckpt, is_best=False, filename=checkpoint_name)\n",
    "\n",
    "\n",
    "# -\n",
    "\n",
    "def train(train_loader, model, model_path, criterion, optimizer, epoch, args, repr_network_params, dhs_list,\n",
    "          dhs_positive_pair_list, overlap_list, loss_list):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top2 = AverageMeter('Acc@2', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top2],\n",
    "        prefix=\"Epoch: [{}/{}]\".format(epoch, args.epochs))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    batch_acc2_list.clear()\n",
    "    \n",
    "    for batch_index, (images, _) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # Wipe the previous quantum statevectors\n",
    "        if hasattr(model.encoder.repr_network[0], 'qnn'):\n",
    "            model.encoder.repr_network[0].qnn.statevectors = []\n",
    "\n",
    "        # Labels are NOT used for training, only for quantum metrics\n",
    "        labels = _\n",
    "\n",
    "        target = torch.zeros(2 * args.batch_size, dtype=torch.long)\n",
    "        if args.gpu is not None:\n",
    "            images[0] = images[0].cuda(args.gpu, non_blocking=True)\n",
    "            images[1] = images[1].cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output [B, D]\n",
    "        out_1 = model(x=images[0])\n",
    "        out_2 = model(x=images[1])\n",
    "\n",
    "        # [2*B, D]\n",
    "        out = torch.cat([out_1, out_2], dim=0)\n",
    "\n",
    "        # [2*B, 2*B]\n",
    "        sim_matrix = torch.exp(torch.mm(out, out.t().contiguous()) / args.temperature)\n",
    "        mask = (torch.ones_like(sim_matrix) - torch.eye(2 * args.batch_size, device=sim_matrix.device)).type(torch.bool)\n",
    "        # [2*B, 2*B-1]\n",
    "        sim_matrix = sim_matrix.masked_select(mask).view(2 * args.batch_size, -1)\n",
    "        # compute loss\n",
    "        pos_sim = torch.exp(torch.sum(out_1 * out_2, dim=-1) / args.temperature)\n",
    "        # [2*B]\n",
    "        pos_sim = torch.cat([pos_sim, pos_sim], dim=0)\n",
    "\n",
    "        loss = (- torch.log(pos_sim / sim_matrix.sum(dim=-1))).mean()\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # to compute acc, concate the positive and negatives\n",
    "        M = torch.cat([pos_sim.view(2 * args.batch_size, 1), sim_matrix], dim=-1)\n",
    "        acc1, acc2 = accuracy(M, target, topk=(1, 2))\n",
    "        losses.update(loss.item(), images[0].size(0))\n",
    "        top1.update(acc1[0], 2 * args.batch_size)\n",
    "        top2.update(acc2[0], 2 * args.batch_size)\n",
    "        batch_acc2_list.append(top2.avg.item())\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if batch_index % args.print_freq == 0:\n",
    "            progress.display(batch_index)\n",
    "\n",
    "        if args.save_batches:\n",
    "            if batch_index % args.save_freq == 0 or batch_index == np.floor(args.epoch_size / args.batch_size):\n",
    "                fname = 'checkpoint_{:04d}_{:04d}.path.tar'.format(epoch, batch_index)\n",
    "                checkpoint_name = os.path.join(model_path, fname)\n",
    "\n",
    "                ckpt = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'arch': args.arch,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                }\n",
    "                save_checkpoint(ckpt, is_best=False, filename=checkpoint_name)\n",
    "\n",
    "                if not args.identity:\n",
    "                    parameters = list(model.encoder.repr_network[0].parameters())\n",
    "                    repr_network_params.append(parameters[0].detach().cpu().numpy().flatten().tolist())\n",
    "\n",
    "                metrics_name = os.path.join(model_path, 'training_metrics')\n",
    "\n",
    "                if hasattr(model.encoder.repr_network[0], 'qnn'):\n",
    "                    gradients = model.encoder.repr_network[0].qnn.gradients\n",
    "                    if args.q_backend == 'statevector_simulator':\n",
    "                        statevectors = np.array(model.encoder.repr_network[0].qnn.statevectors)\n",
    "                        if args.save_dhs:\n",
    "                            labels = np.array(labels)\n",
    "\n",
    "                            total_labels = np.append(labels, labels)\n",
    "\n",
    "                            class_0_statevectors = statevectors[total_labels == 0]\n",
    "                            class_1_statevectors = statevectors[total_labels != 0]\n",
    "\n",
    "                            rho = np.mean([np.outer(vector, np.conj(vector)) for vector in class_0_statevectors],\n",
    "                                          axis=0)\n",
    "                            sigma = np.mean([np.outer(vector, np.conj(vector)) for vector in class_1_statevectors],\n",
    "                                            axis=0)\n",
    "\n",
    "                            rho_squared = np.trace(matrix_power(rho, 2))\n",
    "                            sigma_squared = np.trace(matrix_power(sigma, 2))\n",
    "                            rho_sigma = np.trace(np.matmul(rho, sigma))\n",
    "                            dhs = np.trace(matrix_power((rho - sigma), 2))\n",
    "                            dhs_list.append([rho_squared.real, sigma_squared.real, rho_sigma.real, dhs.real])\n",
    "\n",
    "                            # Calculate DHS for positive pair as one class\n",
    "                            aug_1_statevectors = statevectors[:int(len(statevectors) / 2)]\n",
    "                            aug_2_statevectors = statevectors[int(len(statevectors) / 2):]\n",
    "\n",
    "                            positive_pairs = list(zip(aug_1_statevectors, aug_2_statevectors))\n",
    "                            rhos = []\n",
    "                            sigmas = []\n",
    "\n",
    "                            for i, positive_pair in enumerate(positive_pairs):\n",
    "                                rho = np.mean([np.outer(vector, np.conj(vector)) for vector in positive_pair], axis=0)\n",
    "                                rhos.append(rho)\n",
    "\n",
    "                                negatives = positive_pairs[:i] + positive_pairs[i + 1:]\n",
    "                                sigma = np.mean(\n",
    "                                    [np.outer(vector, np.conj(vector)) for pair in negatives for vector in pair],\n",
    "                                    axis=0)\n",
    "                                sigmas.append(sigma)\n",
    "\n",
    "                            average_rho_squared = np.mean([np.trace(matrix_power(rho, 2)) for rho in rhos], axis=0)\n",
    "                            average_sigma_squared = np.mean([np.trace(matrix_power(sigma, 2)) for sigma in sigmas],\n",
    "                                                            axis=0)\n",
    "                            average_rho_sigma = np.mean(\n",
    "                                [np.trace(np.matmul(rho, sigma)) for (rho, sigma) in zip(rhos, sigmas)], axis=0)\n",
    "\n",
    "                            average_dhs = np.mean(\n",
    "                                [np.trace(matrix_power((rho - sigma), 2)) for (rho, sigma) in zip(rhos, sigmas)],\n",
    "                                axis=0)\n",
    "\n",
    "                            dhs_positive_pair_list.append(\n",
    "                                [average_rho_squared.real, average_sigma_squared.real, average_rho_sigma.real,\n",
    "                                 average_dhs.real])\n",
    "\n",
    "                        if args.save_overlap:\n",
    "                            aug_1_statevectors = statevectors[:int(len(statevectors) / 2)]\n",
    "                            aug_2_statevectors = statevectors[int(len(statevectors) / 2):]\n",
    "                            positive_pairs_overlaps = [abs(np.dot(np.conj(vec_1), vec_2)) ** 2 for (vec_1, vec_2)\n",
    "                                                       in zip(aug_1_statevectors, aug_2_statevectors)]\n",
    "                            overlap_list.append(np.mean(positive_pairs_overlaps))\n",
    "\n",
    "                else:\n",
    "                    gradients = []\n",
    "                np.save(metrics_name, np.array([loss_list, repr_network_params, gradients, dhs_list,\n",
    "                                                dhs_positive_pair_list, overlap_list], dtype=object))\n",
    "\n",
    "\n",
    "def create_output_model_path(args, version=0):\n",
    "    if args.quantum:\n",
    "        model_path = os.path.join('model', 'selfsup', 'simclr', args.submission_time,\n",
    "                                  'SimCLR-{}-quantum_{}-backend_{}-classes_{}--ansatz_{}-netwidth_{}-nlayers_{}'\n",
    "                                  '-nsweeps_{}-activation_{}-shots_{}-epochsize_{}-bsize_{}-tepochs_{}_{}'.format(\n",
    "                                      args.arch, args.quantum, args.q_backend, args.classes, args.q_ansatz, args.width,\n",
    "                                      args.layers, args.q_sweeps, args.activation, args.shots, args.epoch_size,\n",
    "                                      args.batch_size, args.epochs, version))\n",
    "    else:\n",
    "        model_path = os.path.join('model', 'selfsup', 'simclr', args.submission_time,\n",
    "                                  'SimCLR-{}-quantum_{}-classes_{}-netwidth_{}-nlayers_{}-identity_{}-epochsize_{}-'\n",
    "                                  'bsize_{}-tepochs_{}_{}'.format(\n",
    "                                      args.arch, args.quantum, args.classes, args.width, args.layers, args.identity,\n",
    "                                      args.epoch_size, args.batch_size, args.epochs, version))\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        return create_output_model_path(args, version=version + 1)\n",
    "    else:\n",
    "        os.makedirs(model_path)\n",
    "        return model_path\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        logging.info('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    lr = args.lr\n",
    "    for milestone in args.schedule:\n",
    "        lr *= 0.1 if epoch >= milestone else 1.\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1, 2)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "# +\n",
    "def print_loss(train_loss):\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(train_loss,  label = \"Training\") # training loss curve\n",
    "    #plt.plot(test_loss,  label = \"Validation\") # training loss curve\n",
    "    plt.legend(loc = 'upper left')\n",
    "    fig = plt.gcf() # get current figure\n",
    "    plt.show()\n",
    "    return fig\n",
    "    \n",
    "def print_acc(train_acc):\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy(%)')\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(train_acc,  label = \"Training\") # training loss curve\n",
    "    #plt.plot(test_acc,  label = \"Validation\") # training loss curve\n",
    "    plt.legend(loc = 'upper left')\n",
    "    fig = plt.gcf() # get current figure\n",
    "    plt.show()\n",
    "    return fig\n",
    "    \n",
    "def save_result_fig(args, name, version=0):\n",
    "    result_path = os.path.join('results', \"Allen's Result\", \"SOCOFing_Fingerprint\",\n",
    "                                  'epochsize_{}-bsize_{}-tepochs_{}_{}_{}_Fig.jpg'.format(args.epoch_size, args.batch_size, args.epochs, name, version))\n",
    "    if os.path.exists(result_path):\n",
    "        return save_result_fig(args, name, version+1)\n",
    "    else:    \n",
    "        return result_path\n",
    "\n",
    "\n",
    "# +\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig_loss = print_loss(train_loss_list)\n",
    "fig_loss_path = save_result_fig(args, \"Loss\")\n",
    "fig_acc = print_acc(train_acc2_list)\n",
    "fig_acc_path = save_result_fig(args, \"Acc\")\n",
    " # 將訓練結果存起來\n",
    "fig_loss.savefig(fig_loss_path, bbox_inches='tight')\n",
    "fig_acc.savefig(fig_acc_path, bbox_inches='tight')\n",
    "# -\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
